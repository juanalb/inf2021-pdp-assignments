%pyspark
from pyspark.sql.types import BooleanType
from pyspark.sql.functions import expr
from pyspark.sql.functions import round

# Load in data
rdd = sc.textFile('./titanic.csv')

# Substract header
header = rdd.first()
header = header.split(",")

# Split on csv delimiter
rdd = rdd.map(lambda line: line.split(","))

# Convert to dataframe
df = rdd.filter(lambda row : row != header).toDF(header)

# Change schema to hold correct types
df = df.withColumn("Survived", df["Survived"].cast("boolean"))
df = df.withColumn("Age", df["Age"].cast("int"))
df = df.withColumn("Siblings/Spouses Aboard", df["Siblings/Spouses Aboard"].cast("int"))
df = df.withColumn("Parents/Children Aboard", df["Parents/Children Aboard"].cast("int"))
df = df.withColumn("Fare", df["Fare"].cast("int"))
df.show(5)
print "TOTAL NUMBER OF RECORDS:", df.count()

# Get the total number of records per passenger class/sex combination
class_sex_count = df.groupby(['Pclass', 'Sex']).count()
print("TOTAL NUMBER OF RECORDS PER PASSENGER CLASS/SEX COMBINATION")
class_sex_count.show()

# Get the total number of records per passenger class/sex combination that survived
survived = df.groupby(['Pclass', 'Sex', 'Survived']).count().withColumnRenamed("count","count_survived")
survived = survived[(survived['Survived'] == True)]
print("TOTAL NUMBER OF RECORDS PER PASSENGER CLASS/SEX COMBINATION THAT SURVIVED")
survived.show()

# Merge the two datasets as preparation for calculating the probabillities
probabillity = class_sex_count.join(survived, on=['Pclass', 'Sex'])
probabillity.select("Pclass", "Sex", "Survived", "count", "count_survived")

# Calculate the probabillities
probabillity = probabillity.withColumn('Probabillity', expr("count_survived / count"))
probabillity = probabillity.withColumn("Probabillity", round(probabillity["Probabillity"], 2))
print("PROBABILLITIES OF A PASSENGER SURVIVING GIVEN THEIR PASSENGER CLASS AND SEX")
probabillity.show()
